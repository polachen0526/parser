0 class_name              InputLayer + Conv2D + BatchNormalization + LeakyReLU + MaxPooling2D
0 input_channel           3
0 input_feature_size      256
0 output_channel          16
0 output_feature_size     128
0 kernel_size             3
0 kernel_stride           1
0 padding                 same
0 activate                linear
0 pool_size               2
0 pool_stride             2
0 pool_padding            same
0 units                   -1
0 Have_bias               0
0 weight_address          0
0 input_padding_size      1
0 output_padding_size     1
0 input_tile_number       8
0 input_tile_size         32
0 output_tile_number      4
0 output_tile_size        16
0 next_tile_size          32
0 branch_input_tile_size  32
0 input_address           index0:0

0 output_address          -1
0 pool_address            1048576
0 Leaky_ReLU_alpha        0.100000001490116119
0 Have_BatchNormalization 1
0 Have_ReLU               1
0 Have_Flatten            0
0 Have_Dense              0
0 Have_Maxpooling         1
0 Have_Concat             0
0 Have_Upsample           0
0 Upsample_size           0
0 weight name             conv2d_1
0 node name               conv2d_1
0 Previous_node_OCH       3
0 Is_LeakyReLU            1
0 Batch_First             1
0 quant_batch_bias        10
0 quant_finish            0
0 pooling_quant_finish    0
0 quant_batch             10
0 quant_word_size         0
0 quant_obuf              10
0 Concat_output_control   0
0 branch_node             0
-----------------------------------------------------
1 class_name              Conv2D + BatchNormalization + LeakyReLU + MaxPooling2D
1 input_channel           16
1 input_feature_size      128
1 output_channel          32
1 output_feature_size     64
1 kernel_size             3
1 kernel_stride           1
1 padding                 same
1 activate                linear
1 pool_size               2
1 pool_stride             2
1 pool_padding            same
1 units                   -1
1 Have_bias               0
1 weight_address          2368
1 input_padding_size      1
1 output_padding_size     1
1 input_tile_number       4
1 input_tile_size         32
1 output_tile_number      2
1 output_tile_size        16
1 next_tile_size          32
1 branch_input_tile_size  32
1 input_address           index0:1048576

1 output_address          -1
1 pool_address            1572864
1 Leaky_ReLU_alpha        0.100000001490116119
1 Have_BatchNormalization 1
1 Have_ReLU               1
1 Have_Flatten            0
1 Have_Dense              0
1 Have_Maxpooling         1
1 Have_Concat             0
1 Have_Upsample           0
1 Upsample_size           0
1 weight name             conv2d_2
1 node name               conv2d_2
1 Previous_node_OCH       16
1 Is_LeakyReLU            1
1 Batch_First             1
1 quant_batch_bias        10
1 quant_finish            0
1 pooling_quant_finish    -2
1 quant_batch             10
1 quant_word_size         0
1 quant_obuf              10
1 Concat_output_control   0
1 branch_node             0
-----------------------------------------------------
2 class_name              Conv2D + BatchNormalization + LeakyReLU + MaxPooling2D
2 input_channel           32
2 input_feature_size      64
2 output_channel          64
2 output_feature_size     32
2 kernel_size             3
2 kernel_stride           1
2 padding                 same
2 activate                linear
2 pool_size               2
2 pool_stride             2
2 pool_padding            same
2 units                   -1
2 Have_bias               0
2 weight_address          11712
2 input_padding_size      1
2 output_padding_size     1
2 input_tile_number       2
2 input_tile_size         32
2 output_tile_number      1
2 output_tile_size        16
2 next_tile_size          32
2 branch_input_tile_size  32
2 input_address           index0:1572864

2 output_address          -1
2 pool_address            1835008
2 Leaky_ReLU_alpha        0.100000001490116119
2 Have_BatchNormalization 1
2 Have_ReLU               1
2 Have_Flatten            0
2 Have_Dense              0
2 Have_Maxpooling         1
2 Have_Concat             0
2 Have_Upsample           0
2 Upsample_size           0
2 weight name             conv2d_3
2 node name               conv2d_3
2 Previous_node_OCH       32
2 Is_LeakyReLU            1
2 Batch_First             1
2 quant_batch_bias        12
2 quant_finish            0
2 pooling_quant_finish    0
2 quant_batch             12
2 quant_word_size         0
2 quant_obuf              12
2 Concat_output_control   0
2 branch_node             0
-----------------------------------------------------
3 class_name              Conv2D + BatchNormalization + LeakyReLU + MaxPooling2D
3 input_channel           64
3 input_feature_size      32
3 output_channel          128
3 output_feature_size     16
3 kernel_size             3
3 kernel_stride           1
3 padding                 same
3 activate                linear
3 pool_size               2
3 pool_stride             2
3 pool_padding            same
3 units                   -1
3 Have_bias               0
3 weight_address          48832
3 input_padding_size      1
3 output_padding_size     1
3 input_tile_number       1
3 input_tile_size         32
3 output_tile_number      1
3 output_tile_size        16
3 next_tile_size          16
3 branch_input_tile_size  32
3 input_address           index0:1835008

3 output_address          -1
3 pool_address            1966080
3 Leaky_ReLU_alpha        0.100000001490116119
3 Have_BatchNormalization 1
3 Have_ReLU               1
3 Have_Flatten            0
3 Have_Dense              0
3 Have_Maxpooling         1
3 Have_Concat             0
3 Have_Upsample           0
3 Upsample_size           0
3 weight name             conv2d_4
3 node name               conv2d_4
3 Previous_node_OCH       64
3 Is_LeakyReLU            1
3 Batch_First             1
3 quant_batch_bias        12
3 quant_finish            0
3 pooling_quant_finish    0
3 quant_batch             12
3 quant_word_size         0
3 quant_obuf              12
3 Concat_output_control   0
3 branch_node             0
-----------------------------------------------------
4 class_name              Conv2D + BatchNormalization + LeakyReLU + MaxPooling2D
4 input_channel           128
4 input_feature_size      16
4 output_channel          256
4 output_feature_size     8
4 kernel_size             3
4 kernel_stride           1
4 padding                 same
4 activate                linear
4 pool_size               2
4 pool_stride             2
4 pool_padding            same
4 units                   -1
4 Have_bias               0
4 weight_address          196800
4 input_padding_size      1
4 output_padding_size     1
4 input_tile_number       1
4 input_tile_size         16
4 output_tile_number      1
4 output_tile_size        8
4 next_tile_size          8
4 branch_input_tile_size  16
4 input_address           index0:1966080

4 output_address          2031616
4 pool_address            2162688
4 Leaky_ReLU_alpha        0.100000001490116119
4 Have_BatchNormalization 1
4 Have_ReLU               1
4 Have_Flatten            0
4 Have_Dense              0
4 Have_Maxpooling         1
4 Have_Concat             0
4 Have_Upsample           0
4 Upsample_size           0
4 weight name             conv2d_5
4 node name               conv2d_5
4 Previous_node_OCH       128
4 Is_LeakyReLU            1
4 Batch_First             1
4 quant_batch_bias        12
4 quant_finish            1
4 pooling_quant_finish    0
4 quant_batch             12
4 quant_word_size         0
4 quant_obuf              12
4 Concat_output_control   1
4 branch_node             0
-----------------------------------------------------
5 class_name              Conv2D + BatchNormalization + LeakyReLU
5 input_channel           256
5 input_feature_size      8
5 output_channel          256
5 output_feature_size     8
5 kernel_size             3
5 kernel_stride           1
5 padding                 same
5 activate                linear
5 pool_size               -1
5 pool_stride             -1
5 pool_padding            none
5 units                   -1
5 Have_bias               0
5 weight_address          787648
5 input_padding_size      1
5 output_padding_size     1
5 input_tile_number       1
5 input_tile_size         8
5 output_tile_number      1
5 output_tile_size        8
5 next_tile_size          8
5 branch_input_tile_size  8
5 input_address           index0:2162688

5 output_address          2195456
5 pool_address            0
5 Leaky_ReLU_alpha        0.100000001490116119
5 Have_BatchNormalization 1
5 Have_ReLU               1
5 Have_Flatten            0
5 Have_Dense              0
5 Have_Maxpooling         0
5 Have_Concat             0
5 Have_Upsample           0
5 Upsample_size           0
5 weight name             conv2d_6
5 node name               conv2d_6
5 Previous_node_OCH       256
5 Is_LeakyReLU            1
5 Batch_First             1
5 quant_batch_bias        12
5 quant_finish            0
5 pooling_quant_finish    0
5 quant_batch             12
5 quant_word_size         0
5 quant_obuf              12
5 Concat_output_control   0
5 branch_node             0
-----------------------------------------------------
6 class_name              Conv2D + BatchNormalization + LeakyReLU
6 input_channel           256
6 input_feature_size      8
6 output_channel          256
6 output_feature_size     8
6 kernel_size             3
6 kernel_stride           1
6 padding                 same
6 activate                linear
6 pool_size               -1
6 pool_stride             -1
6 pool_padding            none
6 units                   -1
6 Have_bias               0
6 weight_address          1968320
6 input_padding_size      1
6 output_padding_size     1
6 input_tile_number       1
6 input_tile_size         8
6 output_tile_number      1
6 output_tile_size        8
6 next_tile_size          8
6 branch_input_tile_size  8
6 input_address           index0:2195456

6 output_address          2228224
6 pool_address            0
6 Leaky_ReLU_alpha        0.100000001490116119
6 Have_BatchNormalization 1
6 Have_ReLU               1
6 Have_Flatten            0
6 Have_Dense              0
6 Have_Maxpooling         0
6 Have_Concat             0
6 Have_Upsample           0
6 Upsample_size           0
6 weight name             conv2d_7
6 node name               conv2d_7
6 Previous_node_OCH       256
6 Is_LeakyReLU            1
6 Batch_First             1
6 quant_batch_bias        12
6 quant_finish            0
6 pooling_quant_finish    0
6 quant_batch             12
6 quant_word_size         0
6 quant_obuf              12
6 Concat_output_control   0
6 branch_node             0
-----------------------------------------------------
7 class_name              Conv2D + BatchNormalization + LeakyReLU
7 input_channel           256
7 input_feature_size      8
7 output_channel          64
7 output_feature_size     8
7 kernel_size             1
7 kernel_stride           1
7 padding                 same
7 activate                linear
7 pool_size               -1
7 pool_stride             -1
7 pool_padding            none
7 units                   -1
7 Have_bias               0
7 weight_address          3148992
7 input_padding_size      0
7 output_padding_size     0
7 input_tile_number       1
7 input_tile_size         8
7 output_tile_number      1
7 output_tile_size        8
7 next_tile_size          8
7 branch_input_tile_size  8
7 input_address           index0:2228224

7 output_address          2262016
7 pool_address            0
7 Leaky_ReLU_alpha        0.100000001490116119
7 Have_BatchNormalization 1
7 Have_ReLU               1
7 Have_Flatten            0
7 Have_Dense              0
7 Have_Maxpooling         0
7 Have_Concat             0
7 Have_Upsample           0
7 Upsample_size           0
7 weight name             conv2d_8
7 node name               conv2d_8
7 Previous_node_OCH       256
7 Is_LeakyReLU            1
7 Batch_First             1
7 quant_batch_bias        12
7 quant_finish            0
7 pooling_quant_finish    0
7 quant_batch             12
7 quant_word_size         0
7 quant_obuf              12
7 Concat_output_control   1
7 branch_node             0
-----------------------------------------------------
8 class_name              Conv2D + BatchNormalization + LeakyReLU
8 input_channel           64
8 input_feature_size      8
8 output_channel          128
8 output_feature_size     8
8 kernel_size             3
8 kernel_stride           1
8 padding                 same
8 activate                linear
8 pool_size               -1
8 pool_stride             -1
8 pool_padding            none
8 units                   -1
8 Have_bias               0
8 weight_address          3187296
8 input_padding_size      1
8 output_padding_size     1
8 input_tile_number       1
8 input_tile_size         8
8 output_tile_number      1
8 output_tile_size        8
8 next_tile_size          8
8 branch_input_tile_size  8
8 input_address           index0:2262016

8 output_address          2270208
8 pool_address            0
8 Leaky_ReLU_alpha        0.100000001490116119
8 Have_BatchNormalization 1
8 Have_ReLU               1
8 Have_Flatten            0
8 Have_Dense              0
8 Have_Maxpooling         0
8 Have_Concat             0
8 Have_Upsample           0
8 Upsample_size           0
8 weight name             conv2d_9
8 node name               conv2d_9
8 Previous_node_OCH       64
8 Is_LeakyReLU            1
8 Batch_First             1
8 quant_batch_bias        12
8 quant_finish            2
8 pooling_quant_finish    0
8 quant_batch             12
8 quant_word_size         0
8 quant_obuf              12
8 Concat_output_control   0
8 branch_node             0
-----------------------------------------------------
9 class_name              Conv2D
9 input_channel           128
9 input_feature_size      8
9 output_channel          18
9 output_feature_size     8
9 kernel_size             1
9 kernel_stride           1
9 padding                 same
9 activate                linear
9 pool_size               -1
9 pool_stride             -1
9 pool_padding            none
9 units                   -1
9 Have_bias               1
9 weight_address          3335264
9 input_padding_size      0
9 output_padding_size     0
9 input_tile_number       1
9 input_tile_size         8
9 output_tile_number      1
9 output_tile_size        8
9 next_tile_size          8
9 branch_input_tile_size  8
9 input_address           index0:2270208

9 output_address          2288640
9 pool_address            0
9 Leaky_ReLU_alpha        -1.000000000000000000
9 Have_BatchNormalization 0
9 Have_ReLU               0
9 Have_Flatten            0
9 Have_Dense              0
9 Have_Maxpooling         0
9 Have_Concat             0
9 Have_Upsample           0
9 Upsample_size           0
9 weight name             conv2d_10
9 node name               conv2d_10
9 Previous_node_OCH       128
9 Is_LeakyReLU            0
9 Batch_First             0
9 quant_batch_bias        10
9 quant_finish            0
9 pooling_quant_finish    0
9 quant_batch             10
9 quant_word_size         0
9 quant_obuf              10
9 Concat_output_control   0
9 branch_node             0
-----------------------------------------------------
10 class_name              Conv2D + BatchNormalization + LeakyReLU + UpSampling2D
10 input_channel           64
10 input_feature_size      8
10 output_channel          32
10 output_feature_size     16
10 kernel_size             1
10 kernel_stride           1
10 padding                 same
10 activate                linear
10 pool_size               -1
10 pool_stride             -1
10 pool_padding            none
10 units                   -1
10 Have_bias               0
10 weight_address          3342272
10 input_padding_size      0
10 output_padding_size     0
10 input_tile_number       1
10 input_tile_size         8
10 output_tile_number      1
10 output_tile_size        16
10 next_tile_size          16
10 branch_input_tile_size  16
10 input_address           index0:2262016

10 output_address          2325504
10 pool_address            0
10 Leaky_ReLU_alpha        0.100000001490116119
10 Have_BatchNormalization 1
10 Have_ReLU               1
10 Have_Flatten            0
10 Have_Dense              0
10 Have_Maxpooling         0
10 Have_Concat             0
10 Have_Upsample           1
10 Upsample_size           2
10 weight name             conv2d_11
10 node name               conv2d_11
10 Previous_node_OCH       64
10 Is_LeakyReLU            1
10 Batch_First             1
10 quant_batch_bias        12
10 quant_finish            1
10 pooling_quant_finish    0
10 quant_batch             12
10 quant_word_size         0
10 quant_obuf              12
10 Concat_output_control   0
10 branch_node             1
-----------------------------------------------------
11 class_name              Concatenate + Conv2D + BatchNormalization + LeakyReLU
11 input_channel           288
11 input_feature_size      16
11 output_channel          128
11 output_feature_size     16
11 kernel_size             3
11 kernel_stride           1
11 padding                 same
11 activate                linear
11 pool_size               -1
11 pool_stride             -1
11 pool_padding            none
11 units                   -1
11 Have_bias               0
11 weight_address          3349376
11 input_padding_size      1
11 output_padding_size     0
11 input_tile_number       1
11 input_tile_size         16
11 output_tile_number      1
11 output_tile_size        16
11 next_tile_size          16
11 branch_input_tile_size  16
11 input_address           index0:2325504
index1:2031616

11 output_address          2472960
11 pool_address            0
11 Leaky_ReLU_alpha        0.100000001490116119
11 Have_BatchNormalization 1
11 Have_ReLU               1
11 Have_Flatten            0
11 Have_Dense              0
11 Have_Maxpooling         0
11 Have_Concat             1
11 Have_Upsample           0
11 Upsample_size           0
11 weight name             conv2d_12
11 node name               conv2d_12
11 Previous_node_OCH       32
11 Previous_node_OCH       256
11 Is_LeakyReLU            1
11 Batch_First             1
11 quant_batch_bias        11
11 quant_finish            2
11 pooling_quant_finish    0
11 quant_batch             11
11 quant_word_size         0
11 quant_obuf              11
11 Concat_output_control   0
11 branch_node             1
-----------------------------------------------------
12 class_name              Conv2D
12 input_channel           128
12 input_feature_size      16
12 output_channel          18
12 output_feature_size     16
12 kernel_size             1
12 kernel_stride           1
12 padding                 same
12 activate                linear
12 pool_size               -1
12 pool_stride             -1
12 pool_padding            none
12 units                   -1
12 Have_bias               1
12 weight_address          4013440
12 input_padding_size      0
12 output_padding_size     0
12 input_tile_number       1
12 input_tile_size         16
12 output_tile_number      1
12 output_tile_size        16
12 next_tile_size          16
12 branch_input_tile_size  16
12 input_address           index0:2472960

12 output_address          2546688
12 pool_address            0
12 Leaky_ReLU_alpha        -1.000000000000000000
12 Have_BatchNormalization 0
12 Have_ReLU               0
12 Have_Flatten            0
12 Have_Dense              0
12 Have_Maxpooling         0
12 Have_Concat             0
12 Have_Upsample           0
12 Upsample_size           0
12 weight name             conv2d_13
12 node name               conv2d_13
12 Previous_node_OCH       128
12 Is_LeakyReLU            0
12 Batch_First             0
12 quant_batch_bias        9
12 quant_finish            0
12 pooling_quant_finish    0
12 quant_batch             9
12 quant_word_size         0
12 quant_obuf              9
12 Concat_output_control   0
12 branch_node             0
-----------------------------------------------------

